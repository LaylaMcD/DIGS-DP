{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd1xtF0qsVYRHYooXWX3pr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaylaMcD/DIGS-DP/blob/main/Word2Vec_Pt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o8Mpn15wYR1u"
      },
      "outputs": [],
      "source": [
        "# imports and set up logging\n",
        "import gensim\n",
        "import logging\n",
        "import glob, os\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jHAzn74Yv-l",
        "outputId": "cdbd898e-d4a2-4cde-85a4-02b8f6501cd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# directory containing all source texts for training the model\n",
        "data_dir=\"/content/drive/My Drive/Colab Notebooks/output_files\""
      ],
      "metadata": {
        "id": "wjsmGmz3Yuew"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(data_dir)\n",
        "documents = list()\n",
        "for filename in glob.glob(\"*.txt\"):\n",
        "    filedata = open(filename, 'r').read()\n",
        "    print(filename + \" = \" + str(len(filedata)) + \" chars\")\n",
        "    documents = documents + filedata.split(\".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBO43g37ZCv6",
        "outputId": "eb3f8163-4707-43d2-8f11-51bab26eb492"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk_6.txt = 2625232 chars\n",
            "chunk_4.txt = 2643870 chars\n",
            "chunk_7.txt = 3051987 chars\n",
            "chunk_2.txt = 2889349 chars\n",
            "chunk_8.txt = 2336498 chars\n",
            "chunk_3.txt = 2559872 chars\n",
            "chunk_1.txt = 2792133 chars\n",
            "chunk_5.txt = 2774493 chars\n",
            "chunk_10.txt = 2428297 chars\n",
            "chunk_9.txt = 2417660 chars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#is that first sentence correct?\n",
        "print(documents[0])\n",
        "\n",
        "docs2 = []\n",
        "# remove all the \"\\n\"s\n",
        "for doc in documents:\n",
        "    newdoc = doc.replace(\"\\n\", \" \")\n",
        "    docs2.append(newdoc)\n",
        "\n",
        "print(docs2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyL4t7wgZGxW",
        "outputId": "da6405e0-4774-4831-a64d-27df6dd9fa7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Twitter is now turning on its new algorithmic timeline for everyone\n",
            ", with users reporting that the company started turning it on it across the service as early as March 15\n",
            "\"Twitter is now turning on its new algorithmic timeline for everyone , with users reporting that the company started turning it on it across the service as early as March 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec, Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "#documents = [\"the mayor of new york was there\", \"human computer interaction and machine learning has now become a trending research area\",\"human computer interaction is interesting\",\"human computer interaction is a pretty interesting subject\", \"human computer interaction is a great and new subject\", \"machine learning can be useful sometimes\",\"new york mayor was present\", \"I love machine learning because it is a new subject area\", \"human computer interaction helps people to get user friendly applications\"]\n",
        "\n",
        "sentence_stream = [doc.split(\" \") for doc in docs2]  #documents\n",
        "\n",
        "trigram_sentences_project = []\n",
        "\n",
        "bigram = Phraser(Phrases(sentence_stream))\n",
        "trigram = Phraser(Phrases(bigram[sentence_stream]))\n",
        "\n",
        "for sent in sentence_stream:\n",
        "    bigrams_ = bigram[sent]\n",
        "    trigrams_ = trigram[bigram[sent]]\n",
        "    trigram_sentences_project.append(trigrams_)\n",
        "\n",
        "# Set values for various parameters\n",
        "num_features = 300    # Word vector dimensionality\n",
        "min_word_count = 1    # Minimum word count\n",
        "num_workers = 20      # Number of threads to run in parallel\n",
        "context = 8           # Context window size\n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "skip_grams = 1        # 0 for CBOW, 1 for skip-grams\n",
        "\n",
        "model = word2vec.Word2Vec(trigram_sentences_project, workers=num_workers, \\\n",
        "           min_count = min_word_count, \\\n",
        "           window = context, sample = downsampling, sg = skip_grams)\n",
        "\n",
        "\n",
        "vocab = list(model.wv.index_to_key)\n",
        "print(vocab[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4yukVUtZTVG",
        "outputId": "04d86940-f936-4bb5-88a0-8829d9e42241"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'and', 'of', 'to', 'a', 'in', 'is', 'for', 'that', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the total number of items in our model's vocabulary\n",
        "print(len(model.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_vxzQCdaZHn",
        "outputId": "8b98648e-fe1f-471f-f5ea-7226b0bd898f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = \"lady\"\n",
        "model.wv.most_similar (positive=w1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJdLztmTacNo",
        "outputId": "25394d86-61b7-444d-e660-e53a6884515e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girlfriend', 0.9164406061172485),\n",
              " ('mom', 0.9089912176132202),\n",
              " ('ghost', 0.9057749509811401),\n",
              " ('kid', 0.9052375555038452),\n",
              " ('an_old', 0.9045943021774292),\n",
              " ('lover', 0.9038964509963989),\n",
              " ('boy', 0.9038270115852356),\n",
              " ('sexy', 0.9033171534538269),\n",
              " ('boyfriend', 0.8983889222145081),\n",
              " ('stranger', 0.8977368474006653)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"ghost\" is certainly interesting..."
      ],
      "metadata": {
        "id": "OtBoYc_MaoIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = \"king\"\n",
        "model.wv.most_similar (positive=w1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agAESTh6aqqk",
        "outputId": "fc58adc4-c273-4abd-e9fa-374f024fc4a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.9430097937583923),\n",
              " ('easter_decorations_for_sale', 0.9366862177848816),\n",
              " ('centerpieces', 0.9351146221160889),\n",
              " ('toddler', 0.9335649609565735),\n",
              " ('home_decor', 0.930773913860321),\n",
              " ('bedroom_ideas', 0.9292471408843994),\n",
              " ('decorating_ideas', 0.9287014007568359),\n",
              " ('easter_decorations_ebay', 0.9242209792137146),\n",
              " ('bedroom_floor_plan', 0.9234209656715393),\n",
              " ('arc_floor_lamp', 0.9233357310295105)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = \"prince\"\n",
        "model.wv.most_similar (positive=w1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqCBcwcaau7C",
        "outputId": "bc7d8f03-8007-4932-c9d7-a501c9765065"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gentleman', 0.9449213743209839),\n",
              " ('stern', 0.9419693350791931),\n",
              " ('hymn', 0.9416805505752563),\n",
              " ('reciting', 0.9405601620674133),\n",
              " ('mythological', 0.9399741888046265),\n",
              " ('Coltraneâ€™s', 0.9396284818649292),\n",
              " ('15-year-old', 0.9385067224502563),\n",
              " ('Jericho', 0.9383893013000488),\n",
              " ('darkly', 0.9370554685592651),\n",
              " ('godmother', 0.9369605779647827)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = \"death\"\n",
        "model.wv.most_similar (positive=w1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKGEzm_taxXQ",
        "outputId": "11a20d7d-9aa4-41fe-ca10-f43cb8dbb43a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('murder', 0.8344448804855347),\n",
              " ('death,', 0.8342791795730591),\n",
              " ('innocent', 0.8179368376731873),\n",
              " ('victim', 0.8175161480903625),\n",
              " ('violent', 0.8161144256591797),\n",
              " ('killing', 0.8105068206787109),\n",
              " ('assault', 0.8075164556503296),\n",
              " ('birth', 0.8075002431869507),\n",
              " ('threatening', 0.8050549030303955),\n",
              " ('guilty', 0.8026435971260071)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.wv.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI7Zsr-aa2NS",
        "outputId": "08ee89cc-502c-4dc1-9afa-6db7ff583b7b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nursery: 0.8705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a different similarity measure: \"cosmul\".\n",
        "result = model.wv.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-tX5GURa330",
        "outputId": "e6ff7f77-bba1-4228-a582-f7bf8720f57c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nursery: 1.0201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does this increase in numbers mean?"
      ],
      "metadata": {
        "id": "4H81xIH9a9vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['he','dies'],negative=['she'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqa0KqKZa8yZ",
        "outputId": "143f2904-1c00-48be-f593-344d370e1811"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('old_man', 0.7500130534172058),\n",
              " ('sword,', 0.7496705651283264),\n",
              " ('teammate', 0.7471629977226257),\n",
              " ('Gardner', 0.7449076175689697),\n",
              " ('grandson', 0.7411761283874512),\n",
              " ('Jeter', 0.7382733225822449),\n",
              " ('McShane', 0.737956166267395),\n",
              " ('spear', 0.7377640604972839),\n",
              " ('third_straight', 0.7374150156974792),\n",
              " ('shook_his', 0.737359881401062)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict_output_word([\"I\",\"die\",\"again\"], topn=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PztLXCc3bHQn",
        "outputId": "3a1b80d8-d3e9-4527-e4b5-22146bfb2709"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('if', 7.627527e-05),\n",
              " ('never', 6.702845e-05),\n",
              " ('I', 6.0757644e-05),\n",
              " ('but', 6.0132068e-05),\n",
              " ('would', 5.751547e-05),\n",
              " ('will', 5.6714973e-05),\n",
              " ('do', 5.524472e-05),\n",
              " ('so', 5.208102e-05),\n",
              " ('should', 5.1377625e-05),\n",
              " ('want_to', 5.0093364e-05),\n",
              " ('went_back', 4.998591e-05),\n",
              " ('you', 4.990742e-05),\n",
              " ('until', 4.909504e-05),\n",
              " ('told_him', 4.8031186e-05),\n",
              " ('my_husband', 4.744889e-05),\n",
              " ('again', 4.7268513e-05),\n",
              " ('my', 4.6656456e-05),\n",
              " ('could_see', 4.648825e-05),\n",
              " ('see', 4.5757624e-05),\n",
              " ('just', 4.5348024e-05),\n",
              " ('then', 4.461459e-05),\n",
              " ('my_hair', 4.424545e-05),\n",
              " (\"couldn't\", 4.4185635e-05),\n",
              " ('looked_at', 4.397541e-05),\n",
              " ('it', 4.375113e-05),\n",
              " ('them', 4.3705662e-05),\n",
              " ('eat', 4.3302727e-05),\n",
              " ('let', 4.3300024e-05),\n",
              " ('it,_but', 4.328994e-05),\n",
              " ('it,', 4.2643238e-05)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "tensorsfp = \"/content/drive/My Drive/Colab Notebooks/output_files/tensorsfp.txt\"\n",
        "metadatafp = \"/content/drive/My Drive/Colab Notebooks/output_files/metadatafp.txt\"\n",
        "\n",
        "with open(tensorsfp, 'w+') as tensors:\n",
        "    with open(metadatafp, 'w+') as metadata:\n",
        "        for word in model.wv.index_to_key:\n",
        "            metadata.write(word + '\\n')\n",
        "            vector_row = model.wv.get_vector(word)\n",
        "\n",
        "            # Convert the numpy array to a string\n",
        "            vector_row_str = np.array2string(vector_row, separator='\\t')\n",
        "\n",
        "            tensors.write(vector_row_str + '\\n')"
      ],
      "metadata": {
        "id": "ZisT7xFNbMVb"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}